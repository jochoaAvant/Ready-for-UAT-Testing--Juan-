{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def rename_and_drop_columns(input_df, column_mapping_df):\n",
    "    # Create a dictionary from the column_mapping dataframe\n",
    "    column_mapping_dict = column_mapping_df.set_index('file_column')['rpm_column'].to_dict()\n",
    "    \n",
    "    # Rename the columns in the manual dataframe\n",
    "    input_df = input_df.rename(columns=column_mapping_dict)\n",
    "    \n",
    "    # Find the columns in the manual dataframe that are not in the column_mapping dataframe\n",
    "    columns_to_drop = [col for col in input_df.columns if col not in column_mapping_dict.values()]\n",
    "    \n",
    "    # Drop the columns that are not in the column_mapping dataframe\n",
    "    input_df = input_df.drop(columns=columns_to_drop)\n",
    "    \n",
    "    return input_df\n",
    "\n",
    "def basic_validation(df1, df2, result_file):\n",
    "    #Remove 'Id' column and 'VIA' Column if any exists\n",
    "    if (any(column_name == 'id' for column_name in df2.columns)): \n",
    "        df2.drop(['id'], axis=1, inplace=True)\n",
    "    if (any(column_name == 'VIA' for column_name in df1.columns)): \n",
    "        df1.drop(['VIA'], axis=1, inplace=True)\n",
    "\n",
    "    # Check if the dataframes have the same number of rows and columns\n",
    "    if df1.shape == df2.shape:\n",
    "        result_file.write(\"The dataframes have the same number of rows and columns.\\n\")\n",
    "    else:\n",
    "        result_file.write(\"The dataframes do not have the same number of rows and columns.\\n\")\n",
    "        result_file.write(f\"The manual dataframe has {df1.shape[0]} rows and {df1.shape[1]} columns.\\n\")\n",
    "        result_file.write(f\"The automated dataframe has {df2.shape[0]} rows and {df2.shape[1]} columns.\\n\")\n",
    "        print (f\"The manual dataframe has {df1.shape[0]} rows and {df1.shape[1]} columns.\\n\")\n",
    "        print (f\"The automated dataframe has {df2.shape[0]} rows and {df2.shape[1]} columns.\\n\")\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "    \n",
    "    # Check if the dataframes have the same columns\n",
    "    if (compare_columns_results := compare_columns(df1, df2, result_file)!=0):\n",
    "        print (compare_columns_results)\n",
    "        return pd.empty, pd.empty\n",
    "    else:\n",
    "        return df1, df2\n",
    "\n",
    "def sort_rows(unsorted_df, columns_to_sort):\n",
    "    # Check if all columns in columns_to_sort exist in the dataframe\n",
    "    if all(item in unsorted_df.columns for item in columns_to_sort):\n",
    "        # Sort the dataframe\n",
    "        df_sorted = unsorted_df.sort_values(list(columns_to_sort)).reset_index(drop=True)\n",
    "        return df_sorted\n",
    "    else:\n",
    "        return \"One or more columns in columns_to_sort do not exist in the dataframe.\"\n",
    "\n",
    "def compare_columns(df1, df2, result_file):\n",
    "    if set(df1.columns) == set(df2.columns):\n",
    "        # Check if corresponding columns in both dataframes have the same data type\n",
    "        for column in df1.columns:\n",
    "            if df1[column].dtype != df2[column].dtype:\n",
    "                print(df1)\n",
    "                result_file.write(f\"The column '{column}' has different data types in the dataframes.\\n\")\n",
    "                print(f\"The column '{column}' has different data types in the dataframes.\")\n",
    "                return f\"The column '{column}' has different data types in the dataframes.\"\n",
    "            else:\n",
    "                result_file.write(\"The dataframes have the same columns and data types.\\n\")\n",
    "                return 0\n",
    "    else:\n",
    "        different_columns = list(set(df1.columns) ^ set(df2.columns))\n",
    "        result_file.write(f\"The dataframes have different columns: {different_columns}\\n\")  \n",
    "        return f\"The dataframes have different columns: {different_columns}\"\n",
    "\n",
    "def compare_df(df1, df2, result_file):\n",
    "    if set(df1.columns) == set(df2.columns):\n",
    " \n",
    "        # Select only numeric columns\n",
    "        df1_numeric = df1.select_dtypes(include=[np.number]).reset_index(drop=True)\n",
    "        df2_numeric = df2.select_dtypes(include=[np.number]).reset_index(drop=True)\n",
    "        \n",
    "        # Create a boolean mask for values in df1_numeric and df2_numeric that are not close\n",
    "        mask = ~np.isclose(df1_numeric.values, df2_numeric.values, atol=0.01)\n",
    "        \n",
    "        # Apply the mask to df1_numeric and df2_numeric, and drop rows that contain only NaN\n",
    "        diff_numeric = df1_numeric.where(mask).compare(df2_numeric.where(mask))\n",
    "        \n",
    "        # Select only non-numeric columns\n",
    "        df1_non_numeric = df1.select_dtypes(exclude=[np.number])\n",
    "        df2_non_numeric = df2.select_dtypes(exclude=[np.number])\n",
    "        \n",
    "        # Compare non-numeric columns\n",
    "        diff_non_numeric = df1_non_numeric.compare(df2_non_numeric)\n",
    "        \n",
    "        # Concatenate the differences\n",
    "        diff = pd.concat([diff_numeric, diff_non_numeric])\n",
    "        \n",
    "        # Reset the index and add the old index as a new column\n",
    "        diff = diff.reset_index().rename(columns={'index': 'original_row_number', 'self': 'manual', 'other': 'automated'})\n",
    "        \n",
    "        if not diff.empty:\n",
    "            result_file.write(f\"The dataframes have differences.\\n\")\n",
    "            return diff\n",
    "        else:\n",
    "            result_file.write(f\"The dataframes have the same columns and values.\\n\")\n",
    "            return \"The dataframes have the same columns and values.\"\n",
    "    else:\n",
    "        different_columns = list(set(df1.columns) ^ set(df2.columns))\n",
    "        return f\"The dataframes have different columns: {different_columns}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m columns_to_sort \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccount\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProduct name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNet billed\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGross commission\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# establish file paths for input and output files\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m manual_url \u001b[38;5;241m=\u001b[39m \u001b[43mPath\u001b[49m(vendor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_files\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrpm_files_manual\u001b[39m\u001b[38;5;124m\"\u001b[39m, filenamem)\n\u001b[0;32m     17\u001b[0m automated_url \u001b[38;5;241m=\u001b[39m Path(vendor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_files\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrpm_files_automation\u001b[39m\u001b[38;5;124m\"\u001b[39m, filenamea)\n\u001b[0;32m     18\u001b[0m output_url \u001b[38;5;241m=\u001b[39m Path(vendor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_files\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m, filename \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_output.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "# def main():    \n",
    "# vendor = input (\"Vendor: \")\n",
    "vendor = 'Appsmart'\n",
    "\n",
    "# filename = input (\"Filename (mmm-yy): \")\n",
    "filename = 'oct-23'\n",
    "\n",
    "# Set variable to 1 to start a new results file, or to 0 to append to an existing file\n",
    "new_file = 1\n",
    "\n",
    "filenamea = filename + 'a.xlsx'\n",
    "filenamem = filename + 'm.xlsx'\n",
    "columns_to_sort = ('Account', 'Product name', 'Net billed', 'Gross commission')\n",
    "\n",
    "# establish file paths for input and output files\n",
    "manual_url = Path(vendor, \"test_files\", \"rpm_files_manual\", filenamem)\n",
    "automated_url = Path(vendor, \"test_files\", \"rpm_files_automation\", filenamea)\n",
    "output_url = Path(vendor, \"test_files\", \"output\", filename + '_output.xlsx')\n",
    "column_mapping_url = Path(vendor, \"test_files\", \"column_mapping.xlsx\")\n",
    "test_results_url = Path(vendor, \"test_files\", \"output\", \"test_results.txt\")\n",
    "\n",
    "\n",
    "\n",
    "# read in the input files\n",
    "try:\n",
    "    manual = pd.read_excel(manual_url)\n",
    "except:\n",
    "    print (\"Error opening manual file\")\n",
    "\n",
    "try:\n",
    "    automated = pd.read_excel(automated_url)\n",
    "except:\n",
    "    print (\"ERROR: opening automated file\")\n",
    "\n",
    "try:\n",
    "    column_mapping = pd.read_excel(column_mapping_url)\n",
    "except:\n",
    "    print (\"ERROR: opening mapping file\")\n",
    "\n",
    "try:\n",
    "    if(new_file):\n",
    "        test_results = open(test_results_url, 'wt')\n",
    "        test_results.write  (f\"Test results for '{vendor}'\\n\")\n",
    "    else:\n",
    "        test_results = open(test_results_url, 'at')\n",
    "except:\n",
    "    print (\"ERROR: opening test results file\")\n",
    "\n",
    "test_results.write  (f\"\\n\\n{'-'*37}\\nTest results for '{vendor}' - '{filename}' \\n\")\n",
    "\n",
    "# run basic validation on the dataframes\n",
    "manual, automated = basic_validation(manual, automated, test_results)\n",
    "\n",
    "if (manual.empty or automated.empty):\n",
    "    print (\"ERROR: Dataframes failed basic validation\")\n",
    "    test_results.write  (\"ERROR: Dataframes failed basic validation\")\n",
    "else:\n",
    "    # Remap columns in manual and automated based on the mapping dataframe\n",
    "    #  this is done to ensure that all files are sorted and compared in the same way\n",
    "    manual = rename_and_drop_columns(manual, column_mapping)\n",
    "    automated = rename_and_drop_columns(automated, column_mapping)\n",
    "\n",
    "    # Sort columns on both dataframes to compare\n",
    "    manual = sort_rows(manual, columns_to_sort)\n",
    "    automated = sort_rows(automated, columns_to_sort)\n",
    "\n",
    "    # Compare the sorted dataframes        \n",
    "    df_differences = compare_df(manual, automated, result_file=test_results)\n",
    "    print(df_differences)\n",
    "\n",
    "    # Produce output files\n",
    "    with pd.ExcelWriter(output_url) as writer:\n",
    "        manual.to_excel(writer, sheet_name='manual', index=False)\n",
    "        automated.to_excel(writer, sheet_name='automated', index=False)\n",
    "    #     if isinstance(df_differences, pd.DataFrame):\n",
    "    #         df_differences.to_excel(writer, sheet_name='differences', index=False)\n",
    "    #     else:\n",
    "    #         pd.DataFrame([df_differences]).to_excel(writer, sheet_name='differences', index=False)\n",
    "\n",
    "    print (\"ERROR: Dataframes failed basic validation\")\n",
    "    test_results.write  (\"ERROR: Dataframes failed basic validation\")\n",
    "test_results.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run the main function\n",
    "# main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
